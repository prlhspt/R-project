df_mpg
# Q3.
df_mpg = mpg %>%
filter(!is.na(drv)& !is.na(cty)) %>%
group_by(drv) %>%
summarise(mean_cty = mean(cty))
mpg <- as.data.frame(ggplot2::mpg)
# Q3.
df_mpg = mpg %>%
filter(!is.na(drv)& !is.na(cty)) %>%
group_by(drv) %>%
summarise(mean_cty = mean(cty))
library(plotly)
library(ggplot2)
library(dplyr)
# Q3.
df_mpg = mpg %>%
filter(!is.na(drv)& !is.na(cty)) %>%
group_by(drv) %>%
summarise(mean_cty = mean(cty))
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
ggplotly(tt)
library(plotly)
install.packages("plotly")
library(plotly)
library(ggplot2)
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
ggplotly(tt)
df_mpg
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
ggplotly(tt)
library(plotly)
install.packages("plotly")
library(plotly)
library(gglot2)
library(ggplot2)
library(plotly)
library(ggplot2)
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
ggplotly(tt)
df_mpg
ggplot(data=df_mpg.aes())
ggplot(data=df_mpg.aes(x=drv,  y=mean_cty))+geom_col()
ggplot(data=df_mpg, aes(x=drv,  y=mean_cty))+geom_col()
ggplot(data=df_mpg, aes(x=drv,  y=mean_cty))+geom_col()+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
ggplot(data=df_mpg, aes(x=drv,  y=mean_cty))+geom_col(fill=rainbow(3))+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
ggplot(data=df_mpg, aes(x=reorder(drv_mean_cty),  y=mean_cty))+geom_col(fill=rainbow(3))+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
ggplot(data=df_mpg, aes(x=reorder(drv.mean_cty),  y=mean_cty))+geom_col(fill=rainbow(3))+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
ggplot(data=df_mpg, aes(x=reorder(drv, mean_cty),  y=mean_cty))+geom_col(fill=rainbow(3))+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
install.packages("plotly")
library(plotly)
install.packages("plotly")
ggplotly(tt)
mpg <- as.data.frame(ggplot2::mpg)
mpg[c(65, 124, 131, 153, 212), "hwy"] <- NA
mpg
library(dplyr)
library(ggplot2)
# Q1.
table(is.na(mpg))
table(is.na(mpg$drv))
table(is.na(mpg$hwy))
# Q2.
mpg %>%
group_by(drv) %>%
filter(!is.na(hwy)) %>%
summarise(mean(hwy, ns.na=T))
# Q1.
mpg <- as.data.frame(ggplot2::mpg)                  # mpg 데이터 불러오기
mpg[c(10, 14, 58, 93), "drv"] <- "k"                # drv 이상치 할당
mpg[c(29, 43, 129, 203), "cty"] <- c(3, 4, 39, 42)  # cty 이상치 할당
table(is.na(mpg))
mpg$drv <- ifelse(mpg$drv %in% c(4, "f", "r"), mpg$drv, NA)
# Q2.
boxplot(mpg$cty)$stats
mpg$cty <- ifelse(mpg$cty < 10 | mpg$cty>25,NA, mpg$cty)
table(is.na(mpg$cty))
boxplot(mpg$cty)$stats
# Q3.
df_mpg = mpg %>%
filter(!is.na(drv)& !is.na(cty)) %>%
group_by(drv) %>%
summarise(mean_cty = mean(cty))
df_mpg
install.packages("plotly")
library(plotly)
library(ggplot2)
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
library(ggplot2)
library(ggplot2)
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(ggplot2)
tt = ggplot(data=df_mpg, aes(x=reorder(drv, -mean_cty), y=mean_cty))+
geom_col(fill=rainbow(3))+coord_flip()
ggplotly(tt)
df_mpg
ggplot(data=df_mpg, aes(x=drv,  y=mean_cty))+geom_col()+coord_flip()+ylab()
install.packages("plotly")
install.packages("plotly")
library(plotly)
library(plotly)
install.packages("plotly")
ggplot(data=mpg, aes(x=displ, y=hwy)) + geom_point()
library(ggplot2)
library(ggplot)
ggplot(data=df_mpg, aes(x=reorder(drv, mean_cty),  y=mean_cty))+geom_col(fill=rainbow(3))+coord_flip()+
ylab("도시연비비")+xlab('구동시간')
ggplotly(tt)
ggplot(data=mpg, aes(x=displ, y=hwy)) + geom_point()
install.packages("plotly")
install.packages("plotly")
install.packages(c("backports", "openssl", "processx"))
install.packages("plotly")
install.packages("plotly")
library(plotly)
install.packages("plotly")
library(plotly)
ggplot(data = mpg, aes(x = displ, y = hwy))+geom_point()+xlim(3, 6)+ylim(10, 20)
midwest=as.data.frame(ggplot2::midwest)
midwest
ggplot(data=midwest.aes(x=poptotal, y=popasian))+geom_point()
ggplot(data=midwest, aes(x=poptotal, y=popasian))+geom_point()
ggplot(data=midwest, aes(x=poptotal, y=popasian))+geom_point()+xlim(0, 5000000)+ylim(0, 10000)
kk=table(mpg$class)
tt=barplot(kk, col=rainbow(8), ylim=c(0, 70))
text(tt, kk, paste0(kk, "대"), pos=3, col=2, cex2)
text(tt, kk, paste0(kk, "대"), pos=3, col=2, cex=2)
text(tt, kk, paste(kk, "대"), pos=3, col=2, cex=2)
text(tt, kk, paste0(kk, "대"), pos=3, col=2, cex=2)
kk=table(mpg$class)
tt=barplot(kk, col=rainbow(8), ylim=c(0, 70))
text(tt, kk, paste(kk, "대"), pos=3, col=2, cex=2)
text(tt, kk, paste0(kk, "대"), pos=3, col=2, cex=2)
tt=barplot(kk, col=rainbow(8), ylim=c(0, 70))
text(tt, kk, paste0(kk, "대"), pos=3, col=2, cex=2)
mpg %>%
filter(class=="suv")
library(ggplot2)
library(dplyr)
mpg %>%
filter(class=="suv")
mpg %>%
filter(class=="suv")
install.packages("plotly")
library(plotly)
install.packages("plotly")
library(ggplot2)
library(plotly)
install.packages("Rtools")
install.packages("plotly")
library(plotly)
setwd("D:/R-workspace/Rdata")
install.packages("rvest")
install.packages("stringr")
library(rvest)
library(stringr)
title=c()
url=c()
press=c()
hdoc=read_html(cr_url)
title=c()
url=c()
press=c()
body=c())
time=c()
body=c()
time=c()
url_b="https://news.daum.net/breakingnews/?page=1"
t_css="#mArticle .tit_thumn .desc_thumb"
pt_css=".info_news"
b_css=".desc_thumb .link_txt"
cr_url=paste0(url_b.1.sep="")
hdoc=read_html(cr_url)
cr_url=paste0(url_b.1.sep="")
hdoc=read_html(cr_url)
t_node=html_nodes(hdoc, t_css)
t_node
cr_url=paste0(url_b.1.sep="")
hdoc=read_html(cr_url)
setwd("D:/R-workspace/Rdata")
install.packages("rvest")
library(rvest)
library(stringr)
title=c()
url=c()
press=c()
body=c()
time=c()
url_b="https://news.daum.net/breakingnews/?page=1"
t_css="#mArticle .tit_thumn .desc_thumb"
pt_css=".info_news"
b_css=".desc_thumb .link_txt"
cr_url=paste0(url_b.1.sep="")
hdoc=read_html(cr_url)
cr_url=paste0(url_b.1, sep="")
cr_url=paste0(url_b, 1, sep="")
hdoc=read_html(cr_url)
t_node=html_nodes(hdoc, t_css)
t_node
pt_node=html_nodes(hodc, pt_css)
pt_node=html_nodes(hdoc, pt_css)
b_node = html_nodes(hdoc)
pt_node=html_nodes(hdoc, pt_css)
b_node = html_nodes(hdoc)
b_node = html_nodes(hdoc, b_css)
url_part=html_attr(t_node, "href")
title_part=html_text
title_part=html_text(t_node)
title_part
cr_url=paste0(url_b, 1, sep="")
hdoc=read_html(cr_url)
t_node=html_nodes(hdoc, t_css)
pt_node=html_nodes(hdoc, pt_css)
b_node = html_nodes(hdoc, b_css)
url_part=html_attr(t_node, "href")
title_part=html_text(t_node)
title_part
pr_part=html.text(pt_node)
pr_part=html_text(pt_node)
time_part=str_sub(pt_part.-5)
pr_part=html_text(pt_node)
title_part=html_text(t_node)
pr_part=html_text(pt_node)
time_part=str_sub(pt_part.-5)
time_part=str_sub(pt_part.-5)
pr_part=html_text(pt_node)
time_part=str_sub(pt_part, -5)
pr_part=html_text(pt_node)
pt_part=html_text(pt_node)
time_part=str_sub(pt_part, -5)
time_part
press_part=str_sub(pt_part, end=-9)
press_part
b_part=html_text(b_node)
b_part
b_part=str_trim(b_part, side="both")
title=c(title, title_part)
press=c(press, press_part)
time=c(time, time_part)
body=c(body, b_part)
url=c(url, url_part)
url=c(url, url_part)
}
news=data.frame(title.press.time.body.url)
body=c(body, b_part)
url=c(url, url_part)
}
news=data.frame(title.press.time.body.url)
news=data.frame(title,press,time,body,url)
news=data.frame(title,press,time,body,url)
title=c(title, title_part)
press=c(press, press_part)
time=c(time, time_part)
body=c(body, b_part)
url=c(url, url_part)
news=data.frame(title,press,time,body,url)
t_css="#mArticle ,tit_thumn ,desc_thumb"
pt_css=".info_news"
b_css=".desc_thumb .link_txt"
cr_url=paste0(url_b, 1, sep="")
t_css="#mArticle ,tit_thumn ,desc_thumb"
url_b="https://news.daum.net/breakingnews/?page=1"
t_css="#mArticle ,tit_thumn ,desc_thumb"
pt_css=".info_news"
b_css=".desc_thumb .link_txt"
cr_url=paste0(url_b, 1, sep="")
hdoc=read_html(cr_url)
t_node=html_nodes(hdoc, t_css)
pt_node=html_nodes(hdoc, pt_css)
b_node = html_nodes(hdoc, b_css)
url_part=html_attr(t_node, "href")
title_part=html_text(t_node)
pt_part=html_text(pt_node)
time_part=str_sub(pt_part, -5)
time_part
press_part=str_sub(pt_part, end=-9)
press_part
b_part=html_text(b_node)
b_part=str_trim(b_part, side="both")
title=c(title, title_part)
press=c(press, press_part)
time=c(time, time_part)
body=c(body, b_part)
url=c(url, url_part)
}
news=data.frame(title,press,time,body,url)
title
press
time
body
url
url_part=html_attr(t_node, "href")
title_part=html_text(t_node)
pt_part=html_text(pt_node)
time_part=str_sub(pt_part, -5)
time_part
title=c(title, title_part)
press=c(press, press_part)
time=c(time, time_part)
body=c(body, b_part)
news=data.frame(title,press,time,body)
write.csv(news, "news0706.csv")
news=data.frame(title,press,time,body)
news=data.frame(title,press,time,body, url)
write.csv(news, "news0706.csv")
View(news)
setwd("D:/R-workspace/Rdata")
library(rvest)
library(stringr)
library(dplyr)
title=c()
rs(list=ls())
title=c()
rm(list=ls())
title=c()
grade=c()
url_b="https://movie.naver.com/movie/point/af/list.nhn?&page=1"
craw_url=paste(url_b)
craw_url=paste(url_b, 1)
craw_url=paste(url_b, 1, Encoding)
craw_url=paste(url_b, 1, Encoding("EUC-KR"))
rm
t_css=".color_b"
library(KoNLP) #최종적으로 "KoNLP" 패키지를 불러옵니다
install.packages("multilinguer")
library(multilinguer)
install_jdk()
install.packages(c('stringr', 'hash', 'tau', 'Sejong', 'RSQLite', 'devtools'),
type = "binary")
install.packages("remotes")
install.packages('rJava', type = 'binary');library(rJava);.jinit();rstudioapi::restartSession()
install.packages("multilinguer")
library(multilinguer)
install_jdk()
install.packages('rJava', type = 'binary');library(rJava);.jinit();rstudioapi::restartSession()
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP', upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
setwd("D:/R-workspace/Rdata")  # <-- 작업 디렉토리는 임의로 지정하세요
install.packages("KoNLP") # 한국어 관련 작업을 할 때 꼭 필요한 기능을 가진 패키지 입니다
install.packages("wordcloud") # Word Cloud 작업을 해 주는 패키지 입니다
install.packages("KoNLP") # 한국어 관련 작업을 할 때 꼭 필요한 기능을 가진 패키지 입니다
library(KoNLP) #최종적으로 "KoNLP" 패키지를 불러옵니다
remotes::install_github('haven-jeon/KoNLP', upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
library(KoNLP) #최종적으로 "KoNLP" 패키지를 불러옵니다
library(KoNLP)  # 설치된 패키지를 Loading 합니다.
library(wordcloud)
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL , type = "source",INSTALL_opts = c('--no-lock'))
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL , type = "source",INSTALL_opts = c('--no-lock'))
txt <- readLines("hong.txt") # txt 라는 변수에 한 줄 씩 읽어 들입니다.
txt <- gsub("저","",txt)  # 제거할 글자를 지정합니다
txt <- gsub("수","",txt)  # 제거할 글자를 지정합니다
txt <- gsub("들","",txt)  # 제거할 글자를 지정합니다
nouns <- sapply(txt,extractNoun,USE.NAMES=F)
nouns <- sapply(txt,extractNoun,USE.NAMES=F)
head(unlist(nouns), 30)
write(unlist(nouns),"hong_2.txt")
rev <- read.table("hong_2.txt")
nrow(rev) # rev 변수에 몇건의 데이터가 있는지 확인해 봅니다
wordcount <- table(rev)
head(sort(wordcount, decreasing=T),30)
library(RColorBrewer) # 화면에 출력할 컬러를 사용할 라이브러리를 Loading 합니다.
palete <- brewer.pal(9,"Set1") # 글자 색깔을 지정합니다.
wordcloud(names(wordcount),freq=wordcount,scale=c(5,0.5),rot.per=0.25,min.freq=1,
random.order=F,random.color=T,colors=palete)
savePlot("hong.png", type="png")
setwd("D:/R-workspace/RData")
library(rvest)
library(stringr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
install.packages("wordcloud2")
library(wordcloud2)
cnt=c()
cnt=c()
b_url="https://www.bskorea.or.kr/bible/korbibReadpage.php?
version=GAE&book=gen&chap="
cr_url=paste0(b_url, 1)
t_css="#td8ible1 span"
hdoc=read_html(cr_url.encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
hdoc=read_html(cr_url.encoding="UTF-8")
hdoc=read_html(cr_url.encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
cnt_part=html_text(n_css)
cnt_part
hdoc=read_html(cr_url.encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
hdoc=read_html(cr_url.encoding="UTF-8")
hdoc=read_html(cr_url, encoding="UTF-8")
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
cr_url=paste0(b_url, 1)
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
b_url="https://www.bskorea.or.kr/bible/korbibReadpage.php?version=GAE&book=gen&chap=1&sec=1"
cr_url=paste0(b_url, 1)
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
cnt_part=html_text(n_css)
cnt_part
cnt_part=gsub("\\d+", ", cnt_part")
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
cnt_part=html_text(n_css)
cnt_part=gsub("\\d+", ", cnt_part")
cnt_part=gsub("\\d+", "", cnt_part")
cnt_part=gsub("\\d+", "", cnt_part")
cnt_part
cnt_part=gsub("\\d+", "", cnt_part")
cnt_part
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part
cnt=c()
b_url="https://www.bskorea.or.kr/bible/korbibReadpage.php?version=GAE&book=gen&chap=1&sec=1"
cr_url=paste0(b_url, 1)
t_css="#td8ible1 span"
hdoc=read_html(cr_url, encoding="UTF-8")
n_css=html_nodes(hdoc, t_css)
cnt_part=html_text(n_css)
cnt_part=gsub("\\d+", "", cnt_part)
cnt_part
cnt=c(cnt, cnt_part)
}
library(KoNLP)
txt=sapply(cnt, extractNoun, USE.NAMES = F)
